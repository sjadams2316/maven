# AI & Investment Advice Regulatory Landscape
## Deep Research for Maven (AI-Native RIA)

*Research Date: February 7, 2026*
*Status: Frontier regulatory territory — rapidly evolving*

---

## Executive Summary

The regulatory framework for AI in investment advice is in a state of significant flux. Key developments:

1. **The SEC's proposed "Predictive Data Analytics" rule (2023) was withdrawn in June 2025** — leaving existing fiduciary framework intact
2. **No AI-specific rules exist** — advisers must apply existing Advisers Act obligations to AI use cases
3. **EU AI Act now in force** — with specific implications for credit scoring and potentially robo-advisory
4. **FINRA Regulatory Notice 24-09** — reminds firms that technology-neutral rules apply to AI
5. **"AI Washing" enforcement actions** — SEC actively pursuing false claims about AI capabilities
6. **Human-in-the-loop expectations** — implicit requirement emerging across guidance

**Bottom line for Maven:** The regulatory approach is "principles-based, not prescriptive." Existing fiduciary duties, disclosure requirements, and compliance obligations apply to AI. The key challenge is documenting how AI recommendations fulfill suitability/best interest standards.

---

## Part 1: Current SEC/FINRA Guidance on Automated Investment Advice

### SEC Guidance Update 2017-02 (The "Robo-Adviser Guidance")

The foundational SEC guidance for automated investment advice remains **IM Guidance Update No. 2017-02** (February 2017). This guidance addresses three core areas:

#### 1. Disclosure Obligations
Robo-advisers should disclose:
- **That an algorithm is utilized** in managing client accounts
- **Algorithm functions** — whether it generates recommendations, implements trades, or rebalances
- **Assumptions and limitations** — e.g., if based on Modern Portfolio Theory, describe its assumptions/limitations
- **Risks inherent in algorithm use** — e.g., rebalancing without regard to market conditions
- **Override circumstances** — when the adviser might halt trading or take defensive measures
- **Third-party involvement** — conflicts if algorithm developers earn fees from recommended products
- **Degree of human involvement** in overseeing accounts

#### 2. Suitability Requirements
The SEC warned that questionnaire-only client intake may be insufficient:
- Questionnaires must elicit **sufficient information** for suitable recommendations
- Consider whether questions are **sufficiently clear** with examples/clarification
- Address **inconsistent client responses** through design features (pop-up boxes, etc.)
- If clients can override recommendations, provide commentary on why certain portfolios may be more appropriate

#### 3. Compliance Programs
Must address unique risks of automated advice:
- **Development, testing, and backtesting** of algorithmic code
- **Post-implementation monitoring** of algorithm performance
- **Disclosure of material changes** to algorithmic code
- **Oversight of third parties** developing/managing algorithms
- **Cybersecurity** protection
- **Electronic marketing** compliance

### FINRA Regulatory Notice 24-09 (June 2024) — Gen AI Guidance

FINRA's key message: **Rules are technology-neutral** — they apply to AI just as they apply to any other technology.

Key points:
- If using Gen AI for **supervision** (e.g., reviewing correspondence), policies must address:
  - Technology governance
  - Model risk management
  - Data privacy and integrity
  - Reliability and accuracy of AI model
- Rules apply whether using **proprietary or third-party AI**
- Use of AI could implicate **virtually every area** of regulatory obligations
- **Rule 3110 (Supervision)** requires supervisory systems tailored to the business
- **Rule 2210 (Communications)** content standards apply whether generated by human or AI

### SEC's Withdrawn Predictive Data Analytics Rule

In July 2023, the SEC proposed rules requiring advisers to:
- **Identify conflicts of interest** when using technology that "optimizes for, predicts, guides, forecasts, or directs investment-related behaviors"
- **Eliminate or neutralize** (not just disclose) such conflicts
- Maintain extensive **documentation and testing** protocols

**This rule was withdrawn June 12, 2025** following the change in SEC leadership. The industry broadly criticized it as:
- Overly broad
- Functionally impossible to comply with
- Stifling of technological innovation

**Implication for Maven:** The elimination/neutralization approach is off the table. Traditional disclosure-and-consent framework applies.

### SEC Exam Priorities (FY 2025)

The SEC flagged AI as an examination focus area:
> "If advisers integrate artificial intelligence into advisory operations, including portfolio management, trading, marketing, and compliance, an examination may look in-depth at compliance policies and procedures as well as disclosures to investors related to these areas."

Examination focus areas:
- Trading functions
- Safekeeping of client records
- Fraud prevention and detection
- Back-office operations
- Anti-money-laundering
- Integration of regulatory technology

### SEC Enforcement: "AI Washing"

The SEC has brought enforcement actions against advisers for **"making false and misleading statements about their purported use of artificial intelligence."**

Key cases (March 2024):
- **Delphia (USA) Inc.** — falsely claimed to use AI in investment decisions
- **Global Predictions, Inc.** — misrepresented AI capabilities

**Key takeaway:** If you don't actually use AI, don't say you do. If you do use AI, don't overstate capabilities.

---

## Part 2: How Existing Robo-Advisors Structure Compliance

### Common Compliance Architecture

Existing robo-advisors generally structure compliance through:

1. **Extensive Form ADV Part 2A Disclosures**
   - Description of algorithmic methodology
   - Limitations of automated advice
   - Circumstances where advice may not be suitable
   - Third-party relationships
   - Conflicts of interest

2. **Client Questionnaires as Suitability Documentation**
   - Risk tolerance assessment
   - Investment time horizon
   - Financial goals
   - Income and net worth
   - Liquidity needs

3. **Automated Surveillance Systems**
   - Portfolio drift monitoring
   - Rebalancing triggers
   - Tax-loss harvesting parameters

4. **Tiered Human Oversight**
   - Algorithmic recommendations for most situations
   - Human review for edge cases
   - Escalation procedures for complex scenarios

### Betterment's Approach

Betterment registers as an SEC-registered investment adviser and:
- Provides detailed disclosures about its algorithm-based methodology
- Uses questionnaires to gather suitability information
- Employs tax-loss harvesting and automatic rebalancing
- Discloses conflicts (e.g., cash allocation earning revenue)
- Faced a **$400,000 FINRA fine** for customer protection rule violations — illustrating regulatory scrutiny

### Wealthfront's Legal Structure

Wealthfront similarly:
- Operates as SEC-registered RIA
- Uses Modern Portfolio Theory-based algorithms
- Provides extensive disclosures about methodology and limitations
- Offers tax-loss harvesting with detailed disclosure of how it works
- Maintains policies for algorithm governance

### Key Compliance Elements Across Industry

| Area | Standard Practice |
|------|------------------|
| Registration | SEC-registered RIA |
| Disclosures | Detailed Form ADV Part 2A on algorithm methodology |
| Suitability | Questionnaire-based client profiling |
| Conflicts | Fee disclosures, revenue sources |
| Oversight | Combination of automated monitoring + human escalation |
| Testing | Pre-deployment and ongoing algorithm testing |
| Records | Retention of recommendations and rationale |

---

## Part 3: Required Disclosures for Algorithmic Recommendations

### Form ADV Part 2A (Brochure) Requirements

Per SEC guidance, AI-driven advisers should disclose:

#### Algorithm Description
- **Methods of analysis** — describe AI/ML techniques used
- **Investment strategies** — how algorithms formulate recommendations
- **Material limitations** — what the AI cannot do or consider

#### Conflict Disclosures
- Third-party algorithm developers and their compensation
- Revenue-sharing arrangements affecting recommendations
- Proprietary products in portfolios
- Use of affiliated services

#### Risk Disclosures
- Algorithm may not perform as expected
- Historical testing doesn't guarantee future results
- Market conditions may exceed algorithm parameters
- Cybersecurity risks
- Model drift possibilities

### Client Relationship Summary (Form CRS)

Should clearly describe:
- Automated nature of advice
- Limited human interaction
- How to access human assistance if needed

### Marketing Rule Compliance (Rule 206(4)-1)

When marketing AI capabilities:
- **No untrue statements** about AI capabilities
- **No misleading implications** about AI sophistication
- **Substantiation required** for performance claims
- **Fair and balanced** presentation of AI benefits and risks

---

## Part 4: Documenting AI-Generated Recommendations

### Recordkeeping Requirements (Rule 204-2)

Investment advisers must maintain records of:
- **Written communications** related to recommendations (Rule 204-2(a)(7))
- Documentation supporting **suitability determinations**
- **Advertising materials** discussing AI (Rule 204-2(a)(11))

### AI-Specific Documentation Best Practices

#### Pre-Deployment Documentation
1. **Algorithm specification documents**
   - Design rationale
   - Data inputs used
   - Model architecture
   - Training methodology
   - Testing results (backtesting, validation)

2. **Risk assessment documentation**
   - Identified risks
   - Mitigation strategies
   - Residual risk acceptance

3. **Approval records**
   - Who approved deployment
   - Conditions for approval
   - Ongoing monitoring requirements

#### Ongoing Documentation
1. **Model performance monitoring**
   - Accuracy metrics over time
   - Drift detection results
   - Retraining decisions

2. **Exception logs**
   - Human overrides of algorithm
   - Escalation decisions
   - Client complaints related to AI

3. **Change documentation**
   - Algorithm modifications
   - Retraining events
   - Data source changes

#### Per-Recommendation Documentation

For each AI-generated recommendation:
- **Input data** — client profile, market data used
- **Algorithm version** — which model made recommendation
- **Output** — the recommendation generated
- **Rationale** — explainability output if available
- **Human review** — whether reviewed and by whom
- **Client communication** — how recommendation was presented

### Audit Trail Best Practices

The SEC Roundtable on AI (March 2025) emphasized:
> "If a regulator or a client asks why a certain recommendation was made, 'the model told me so' is an insufficient answer."

Advisers must be able to:
- Articulate **key factors** driving conclusions
- Explain **assumptions** underlying the model
- Demonstrate **reasonable basis** for advice

---

## Part 5: Proposed and Pending Regulations

### Federal Level (U.S.)

#### SEC — Current Status
- **Predictive Data Analytics Rule: WITHDRAWN** (June 2025)
- No new AI-specific rulemaking pending
- Focus is on **enforcement of existing rules** applied to AI

#### FINRA
- **Regulatory Notice 24-09** (June 2024) — guidance, not new rules
- **2025 Annual Regulatory Oversight Report** — AI as key risk area
- Technology-neutral approach — existing rules apply

#### CFTC
- **Staff Advisory Letter 24-17** (December 2024)
- Nonbinding guidance for derivatives markets
- Emphasizes existing rules apply to AI

#### Executive Branch
- **Biden's EO 14110** on AI — revoked January 2025
- **Trump's EO on AI** (January 2025) — "removing barriers to American leadership in AI"
- Regulatory rollback expected; no new prescriptive rules anticipated

### State Level

#### Colorado SB 24-205
Requires financial institutions to:
- **Disclose how AI-driven lending decisions are made**
- Describe **data sources** informing AI models
- Explain how **performance was evaluated**
- Aims to reduce discrimination in AI-based consequential decisions

**Potential expansion:** May extend to investment advice if pattern continues

### Industry Self-Regulation

#### CFA Institute
- Ethical guidance on AI/ML in investment decision-making
- Emphasis on explainability and bias testing

---

## Part 6: EU AI Act Implications for Wealth Management

### Overview

The **EU AI Act** (Regulation 2024/1689) entered force August 1, 2024, with phased implementation:
- **August 2025:** Prohibited AI practices banned
- **August 2026:** Most obligations take effect

### Classification of Financial AI Systems

#### High-Risk Category (Annex III, Section 5)

Specifically listed as high-risk:
> "(b) AI systems intended to be used to **evaluate the creditworthiness** of natural persons or establish their **credit score**, with the exception of AI systems used for the purpose of detecting financial fraud"

> "(c) AI systems intended to be used for **risk assessment and pricing** in relation to natural persons in the case of life and health insurance"

#### Investment Advice AI — Classification Unclear

**Robo-advisory for investment advice is NOT explicitly listed** in Annex III high-risk categories.

However, the AI Act applies broadly to systems that:
- Make decisions affecting access to services
- Could have significant impact on individuals

**Conservative interpretation:** AI providing personalized investment recommendations could be subject to high-risk requirements if it significantly affects client financial outcomes.

### High-Risk Requirements (If Applicable)

If investment advice AI qualifies as high-risk:

1. **Risk Management System**
   - Identify and mitigate risks throughout lifecycle
   - Address foreseeable misuse

2. **Data Governance**
   - Training data must be relevant, representative, error-free
   - Address potential biases

3. **Technical Documentation**
   - Comprehensive documentation of design decisions
   - Performance metrics and limitations

4. **Human Oversight**
   - Designed to allow human oversight
   - Humans can understand, monitor, and intervene

5. **Accuracy, Robustness, Cybersecurity**
   - Appropriate levels throughout lifecycle
   - Resilient to errors and attacks

6. **Transparency**
   - Instructions for use
   - Capabilities and limitations

7. **Record Keeping**
   - Automatic logging of events

### Extraterritorial Application

The AI Act applies to:
- EU-based entities using AI
- Non-EU entities **supplying AI systems to EU market**
- Non-EU entities if **output is used within EU**

**For Maven:** If serving any EU clients, AI Act compliance may be required.

### Financial Services Carve-outs

The AI Act recognizes existing financial services regulation:
- Financial services entities benefit from **limited derogations** for quality management and monitoring
- Existing EU financial services law governance requirements recognized
- Supervision through **existing financial regulators** (EBA, ESMA, EIOPA)

---

## Part 7: Human-in-the-Loop Requirements

### No Explicit U.S. Regulatory Mandate

There is **no explicit SEC/FINRA rule requiring human oversight** of AI investment recommendations.

However, **implicit expectations** emerge from:

#### Fiduciary Duty
- Cannot delegate fiduciary duty to an algorithm
- Must be able to explain basis for recommendations
- Client's best interest cannot be determined solely by machine

#### SEC Guidance Implications
The 2017 guidance suggests robo-advisers consider disclosing:
> "the degree of human involvement in overseeing and managing client accounts"

This implies human involvement is expected, or lack thereof requires disclosure.

#### SEC Roundtable Takeaways (March 2025)

Key guidance from SEC roundtable participants:
- "Ensure **'human-in-the-loop' oversight** is threaded into AI adoption"
- An adviser **cannot defer its fiduciary responsibility to an algorithm**
- Must **understand the AI tool's function** and limitations
- Ensure outputs are in client's best interest

#### FINRA Rule 3110 (Supervision)

Requires a "reasonably designed supervisory system." If using AI:
- Policies must address **technology governance**
- Human supervision of AI outputs expected
- Cannot rely solely on automated systems

### When Human Oversight is Critical

Based on regulatory guidance and industry practice:

| Situation | Human Review Expectation |
|-----------|-------------------------|
| Initial portfolio recommendation | High — suitability determination |
| Routine rebalancing | Low — within parameters |
| Client complaint | High — judgment required |
| Edge case/unusual client situation | High — algorithm limitations |
| Material changes to client circumstances | High — re-assess suitability |
| Market crisis/extreme conditions | High — override capability |
| Complex financial situations | High — holistic assessment |

### Practical Implementation

For Maven, consider a tiered approach:

**Tier 1 — Fully Automated (Audit Trail Only)**
- Standard rebalancing
- Tax-loss harvesting within parameters
- Dividend reinvestment

**Tier 2 — Automated with Human Review**
- Initial portfolio recommendations
- Client onboarding suitability assessment
- Significant portfolio changes

**Tier 3 — Human Decision with AI Support**
- Complex financial planning
- Client complaints/disputes
- Edge cases flagged by algorithm
- Market crisis situations

---

## Part 8: Model Risk Management Expectations

### Foundational Framework: SR 11-7

While technically applicable only to banks, **Fed/OCC SR 11-7** (Supervisory Letter on Model Risk Management) has become the de facto standard for AI governance in financial services.

Four pillars:
1. **Model Development** — sound methodology, documented
2. **Model Validation** — independent review, testing
3. **Governance** — board/senior management oversight
4. **Monitoring** — ongoing performance tracking, recalibration

### Applying SR 11-7 Principles to Investment Advice AI

#### Model Development
- Document rationale for algorithm design
- Validate data sources and quality
- Test assumptions underlying methodology
- Benchmark against alternative approaches

#### Model Validation
- **Challenger models** — test against simpler approaches
- **Backtesting** — historical performance verification
- **Sensitivity analysis** — how outputs change with inputs
- **Independent review** — separate from development team

#### Governance
- **Senior management approval** for model deployment
- **Regular reporting** on model performance
- **Clear ownership** of model risk
- **Escalation procedures** for issues

#### Monitoring
- **Performance tracking** against benchmarks
- **Drift detection** — identifying degradation over time
- **Trigger-based retraining** when performance drops
- **Periodic comprehensive review** (annual at minimum)

### AI-Specific Considerations

Beyond traditional models, AI/ML requires attention to:

#### Explainability
- Can you explain why the model made a recommendation?
- Are "black box" elements documented?
- What explainability techniques are employed?

#### Bias Detection
- Testing for disparate impact across protected classes
- Monitoring for drift in bias metrics
- Documentation of bias testing methodology

#### Data Provenance
- Where does training data come from?
- How is it validated?
- What are the data's limitations?

#### Version Control
- Which model version is in production?
- What changed between versions?
- How are rollbacks handled?

---

## Part 9: Algorithmic Bias Considerations

### Legal Framework

#### Existing Fair Lending Laws Apply
- **Equal Credit Opportunity Act (ECOA)** — prohibits discrimination in credit
- **Fair Housing Act** — housing-related financial services
- **Civil Rights Act** — general discrimination prohibition

While these focus on lending, **fiduciary duty** extends similar protections to investment advice — advisers cannot discriminate based on protected characteristics.

#### Key Legal Concept: Disparate Impact

Even if AI doesn't explicitly use protected characteristics, it can violate law if:
- It produces **systematically different outcomes** for protected groups
- The difference cannot be justified by legitimate business necessity
- Less discriminatory alternatives exist

### Sources of Bias in Investment AI

1. **Training Data Bias**
   - Historical data reflects past discrimination
   - Underrepresentation of certain groups
   - Biased outcomes in historical recommendations

2. **Proxy Variables**
   - Variables correlated with protected characteristics
   - Examples: ZIP code (race), shopping habits (gender), email format (race/ethnicity)
   - AI may find proxies humans wouldn't consider

3. **Design Choices**
   - How risk is defined and measured
   - What outcomes are optimized for
   - Default assumptions in questionnaires

4. **Feedback Loops**
   - AI learns from own recommendations
   - Initial bias amplified over time

### Testing Requirements

For Maven, consider:

#### Pre-Deployment Testing
- **Disparate impact analysis** across demographic groups
- **Proxy variable identification** — what inputs correlate with protected characteristics?
- **Alternative model comparison** — is there a less biased approach with similar accuracy?

#### Ongoing Monitoring
- **Regular disparate impact testing** (quarterly recommended)
- **Outcome tracking** by demographic (where legally obtainable)
- **Complaint analysis** for bias patterns

#### Documentation
- Bias testing methodology
- Results and findings
- Remediation actions taken
- Ongoing monitoring results

### Regulatory Focus Areas

#### CFPB Activity
- Expanding "unfair" under UDAAP to include algorithmic discrimination
- Planning to review "models, algorithms and decision-making processes"

#### State Attorneys General
- **Massachusetts AG settlement** (2025) against lender for AI bias
- Required testing of algorithmic models for disparate impact
- Required testing of judgmental inputs for fair lending concerns

---

## Part 10: Disclosure of AI Use to Clients

### Current Requirements

**No explicit requirement** to disclose AI use per se, BUT:

#### Form ADV Part 2A
Must disclose:
- **Methods of analysis** — if AI/ML, must describe
- **Investment strategies** — how recommendations are formulated
- **Material risks** — including AI-specific risks

#### Fiduciary Duty
- Client must be able to make **informed decisions**
- Material information about how advice is generated = disclosable
- AI use is likely material to many clients

### Best Practices for AI Disclosure

#### What to Disclose

1. **That AI is used** — clear, prominent statement
2. **How AI is used** — portfolio construction, rebalancing, etc.
3. **Degree of automation** — fully automated vs. human-supervised
4. **Limitations** — what AI cannot consider, when it may fail
5. **Human involvement** — oversight, escalation, override capability
6. **Data used** — what client information feeds the AI
7. **Conflicts** — third-party AI developers, revenue implications

#### How to Disclose

Per SEC guidance:
- **Not buried** — prominently placed
- **Not incomprehensible** — plain language
- **Interactive elements** — pop-ups, tooltips for key concepts
- **Mobile-optimized** — readable on all devices
- **Timely** — before sign-up, not after

### Sample Disclosure Language (Template)

> **Use of Technology in Investment Management**
> 
> Maven uses artificial intelligence and machine learning technology to analyze your financial situation, develop investment recommendations, and manage your portfolio. Our AI system considers your stated risk tolerance, investment goals, time horizon, and financial circumstances to select and maintain an appropriate portfolio.
>
> **How Our Technology Works:** Our proprietary AI analyzes your profile information and market data to recommend a portfolio allocation. The system automatically rebalances your portfolio when it drifts beyond specified parameters and implements tax-loss harvesting strategies.
>
> **Limitations:** Our AI cannot consider factors you have not disclosed to us. It is designed for general investment management and does not provide comprehensive financial planning, tax advice, or estate planning. The AI's recommendations are based on historical patterns that may not predict future results.
>
> **Human Oversight:** While our AI generates recommendations, our investment team reviews the underlying models regularly. A human advisor will review your account under certain circumstances [describe]. You may request to speak with a human advisor at any time.
>
> **Data Privacy:** Information you provide is used to personalize recommendations. [See Privacy Policy for details.]

---

## Part 11: Future Regulatory Trajectory

### Short-Term (2026-2027)

#### United States
- **Enforcement-focused approach** — existing rules applied to AI
- **Principles-based** rather than prescriptive
- **No major new AI-specific rules expected** under current administration
- Potential for **FINRA guidance** on specific use cases
- Continued **AI washing enforcement**

#### European Union
- **August 2026** — High-risk AI obligations take effect
- **Financial services guidance** expected from ESAs
- Potential **clarification** on investment advice classification

### Medium-Term (2027-2030)

Potential developments:
- **Harmonization efforts** between U.S. and EU frameworks
- **State-level AI laws** potentially affecting financial services
- **Industry self-regulation** through CFA Institute, etc.
- Possible **revisiting of Rule 3a-4** (investment company exemption) for robo-advisers

### Wildcard Factors

- **Major AI failure** in financial services could trigger rapid regulation
- **Political shifts** could change regulatory posture
- **Technology advances** (AGI) could force fundamental rethinking

---

## Part 12: Maven-Specific Recommendations

### Immediate Actions

1. **Document your AI architecture**
   - How does the AI generate recommendations?
   - What data does it use?
   - What are its limitations?
   - How is it tested and validated?

2. **Update Form ADV disclosures**
   - Describe AI/ML methodology
   - Disclose limitations clearly
   - Explain human oversight role
   - Address conflicts of interest

3. **Establish compliance policies**
   - Algorithm governance procedures
   - Testing and validation protocols
   - Human oversight triggers
   - Change management processes

4. **Implement recordkeeping**
   - Recommendation audit trails
   - Model version documentation
   - Performance monitoring logs
   - Exception and override records

5. **Train personnel**
   - What the AI can/cannot do
   - When to escalate
   - How to explain recommendations to clients

### Ongoing Compliance

1. **Regular bias testing** — quarterly disparate impact analysis
2. **Model performance monitoring** — drift detection, accuracy tracking
3. **Annual comprehensive review** — full model validation
4. **Stay current** — regulatory developments, enforcement actions

### EU Compliance (If Applicable)

If serving EU clients:
1. **Assess AI Act classification** — likely high-risk considerations
2. **Implement required documentation** — technical documentation
3. **Ensure human oversight capabilities**
4. **Prepare for August 2026 deadline**

---

## Questions for Legal Counsel

1. **Does our AI system require disclosure as a "method of analysis" under Form ADV, and if so, how detailed must the disclosure be?**

2. **What documentation would demonstrate "reasonable basis" for AI-generated recommendations in an SEC examination?**

3. **How should we structure human oversight to satisfy fiduciary obligations without eliminating the efficiency benefits of automation?**

4. **Do any of our AI components trigger Rule 3a-4 considerations under the Investment Company Act?**

5. **If we serve EU clients, does our investment advice AI qualify as "high-risk" under the AI Act?**

6. **What bias testing methodology would satisfy potential fair lending scrutiny if our AI is later applied to any lending-adjacent services?**

7. **How should we handle client consent for AI-driven advice — is affirmative consent required, or is disclosure sufficient?**

8. **What records should we retain to demonstrate AI recommendation rationale in case of client complaints or regulatory inquiries?**

9. **Are there state-level AI regulations (beyond Colorado) that we need to monitor?**

10. **How do we handle situations where the AI recommendation conflicts with what a human advisor might recommend?**

---

## Key Sources and References

### SEC Documents
- IM Guidance Update 2017-02 (Robo-Advisers)
- SEC Press Release 2024-36 (AI Washing Enforcement)
- SEC 2025 Examination Priorities
- SEC Roundtable on AI (March 2025)

### FINRA Documents
- Regulatory Notice 24-09 (June 2024)
- Report on Digital Investment Advice (March 2016)
- 2025 Annual Regulatory Oversight Report

### EU Documents
- AI Act (Regulation 2024/1689)
- Annex III (High-Risk AI Systems)

### Law Firm Resources
- Morrison Foerster: AI Compliance Tips for Investment Advisers (Oct 2025)
- Sidley Austin: U.S. Financial Regulator Guidelines (Feb 2025)
- Goodwin: EU AI Act Key Points for Financial Services (Aug 2024)
- Skadden: SEC Proposes New Conflicts Rule (Aug 2023)
- Dechert: SEC Staff Guidance on Robo-Advisers (Mar 2017)

### Industry Resources
- Kitces.com: AI Compliance Framework (Dec 2025)
- Brookings: Reducing Bias in AI-Based Financial Services (July 2020)
- KPMG: AI and Model Risk Management (Oct 2025)

---

*This document represents research gathered from publicly available sources and should not be construed as legal advice. Consult with qualified legal counsel for specific compliance questions.*
